{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP2_FI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP1PZ/ZQhtdSMJPJkF7fO/S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RonnyGuevara/Fractal_Images/blob/main/TP2/TP2_FI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Práctica 3:  Clasificadores no paramétricos\n",
        "\n",
        "##Presentado por: Ronny Guevara\n",
        "\n",
        "## Objetivo General\n",
        "Desarrollar aplicativos que permitan dar solvencia a los problemas propuestos en la materia.\n",
        "## Objetivos Específicos\n",
        "*   Desarrollar clasificadores supervisados K vecinos más cercanos que den solución a los ejercicios planteados en el trabajo práctico \n",
        "*   Mediante la selección de datos proponer un clasificador supervisado KNN entrenado.\n",
        "*   Visualización de resultados"
      ],
      "metadata": {
        "id": "w9uzgbDa7KgK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Problema\n",
        "El presente trabajo práctico da solución a los siguientes ejercicios:\n",
        "\n",
        "**Ejercicio 1** Supongamos que tenemos un dataset mezcla de dos grupos aleatorios bidimensionales (cada uno con 100 datos, su centroide y covariancia)\n",
        " Encontrar un clasificador por K-NN y evaluar exactitud, precisión, f-measure. Tomar inicialmente un dataset de entrenamiento de N=100 (50+50), k=10, y validar con el resto del dataset. Hacer algunos experimentos con otros N y k, y \n",
        "también cambiando centroide y covariancia de las clases.\n",
        "  *   ¿Cambia mucho si el dataset tiene más dimensiones?\n",
        "\n",
        "**Ejercicio 2** En el notebook https://github.com/manlio99/Materia-de-aprendizaje/blob/master/3_MidtermProjects/musica.ipynb  hay un dataset con 2000+ canciones de Spotify de una usuaria, donde algunas fueron marcadas como gustadas y otras no. Cada canción tiene a su vez 16 atributos (nombre, artista, duración, bailable, etc.)\n",
        "*   Desarrollar un clasificador que prediga si una canción dada va a ser gustada o no. Aclarar y justificar los pasos, analizar y explicar los resultados.\n"
      ],
      "metadata": {
        "id": "bEec-jSC7M_u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Solución\n",
        "Se plantea posibles soluciones, para el primer problema se desarrolla un aplicativo que genera 2 dataset de distribución normal, la media de la distribución, la desviación estándar y el tamaño de la tupla son seleccionadas por el usuario; se concatena y ordena para posterior obtener un clasificador supervisado K-NN, los resultados serán evaluados con n_neighbors = 1 & 10.\n",
        "\n",
        "Para el segundo ejercicio, se muestran los atributos y datos del dataset, se evalúan los atributos que portarán significancia al clasificador mediante la correlación de los datos de cada columna. Visualización de la distribución de los datos mediante scatterplots, tomando como eje X el atributo \"energy\" dado su alta importancia. Posterior, los datos ingresan al clasificador supervisado K-NN sin entrenamiento y se evalúa con n_neighbors = 10.\n",
        "Se normalizan los datos utilizando la función StandardScaler() de sklearn, se entrena al clasificador y se evalúan los resultados con n_neighbors = 10."
      ],
      "metadata": {
        "id": "vIt071xa7Pj0"
      }
    }
  ]
}